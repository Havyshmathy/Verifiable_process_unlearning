{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport random\nimport time\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nset_seed()\nprint(\"Device:\", DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T08:36:23.044266Z","iopub.execute_input":"2026-02-22T08:36:23.044958Z","iopub.status.idle":"2026-02-22T08:36:23.053086Z","shell.execute_reply.started":"2026-02-22T08:36:23.044930Z","shell.execute_reply":"2026-02-22T08:36:23.052366Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"def generate_dataset(time_steps=1500):\n\n    processes = [f\"P{i}\" for i in range(10)]\n    data = []\n\n    for process in processes:\n\n        prev_memory = np.random.uniform(50,150)\n        regime = 0\n\n        for t in range(time_steps):\n\n            if t in [500,1000]:\n                regime = 1 - regime\n\n            noise = np.random.normal(0,3)\n\n            if process==\"P0\":\n                memory = prev_memory + 0.6 + noise*0.3\n\n            elif process==\"P1\":\n                spike = np.random.pareto(2)*30 if np.random.rand()<0.15 else 0\n                memory = prev_memory + spike + noise\n\n            elif process==\"P2\":\n                memory = prev_memory + np.random.normal(0,8)\n\n            elif process==\"P3\":\n                memory = 120 + 45*np.sin(t/10) + noise\n\n            elif process==\"P4\":\n                memory = prev_memory * (1.004 if regime==0 else 0.996)\n\n            elif process==\"P5\":\n                memory = 80 + 40*np.log(t+1)\n\n            elif process==\"P6\":\n                memory = prev_memory - 0.7 + noise\n\n            elif process==\"P7\":\n                memory = prev_memory + (25 if regime else -20) + noise\n\n            elif process==\"P8\":\n                memory = 60 + (t%200)*1.2\n\n            elif process==\"P9\":\n                r=3.9\n                x=np.random.rand()\n                chaotic=r*x*(1-x)\n                memory = prev_memory + chaotic*15\n\n            cpu = np.random.uniform(5,95)\n            data.append([process,t,prev_memory,cpu,memory])\n            prev_memory = memory\n\n    return pd.DataFrame(data,\n        columns=[\"process_id\",\"time_step\",\"previous_memory\",\"cpu_usage\",\"memory_usage_next\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T08:36:25.878223Z","iopub.execute_input":"2026-02-22T08:36:25.878519Z","iopub.status.idle":"2026-02-22T08:36:25.886898Z","shell.execute_reply.started":"2026-02-22T08:36:25.878493Z","shell.execute_reply":"2026-02-22T08:36:25.886143Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class MemoryDataset(Dataset):\n\n    def __init__(self, df, seq_len=15):\n        self.samples=[]\n        self.seq_len=seq_len\n\n        for pid in df[\"process_id\"].unique():\n            proc_df=df[df[\"process_id\"]==pid].sort_values(\"time_step\")\n            for i in range(len(proc_df)-seq_len):\n                window=proc_df.iloc[i:i+seq_len]\n                target=proc_df.iloc[i+seq_len][\"memory_usage_next\"]\n                self.samples.append((window,target))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self,idx):\n        window,target=self.samples[idx]\n        proc=torch.LongTensor(window[\"process_encoded\"].values)\n        feat=torch.FloatTensor(window[[\"previous_memory\",\"cpu_usage\"]].values)\n        y=torch.FloatTensor([target])\n        return proc,feat,y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T08:36:28.474194Z","iopub.execute_input":"2026-02-22T08:36:28.474482Z","iopub.status.idle":"2026-02-22T08:36:28.480614Z","shell.execute_reply.started":"2026-02-22T08:36:28.474457Z","shell.execute_reply":"2026-02-22T08:36:28.479807Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"class DeepLSTM(nn.Module):\n\n    def __init__(self,num_processes):\n        super().__init__()\n\n        self.embedding=nn.Embedding(num_processes,64)\n\n        self.lstm=nn.LSTM(\n            input_size=64+2,\n            hidden_size=128,\n            num_layers=3,\n            dropout=0.3,\n            batch_first=True\n        )\n\n        self.fc=nn.Sequential(\n            nn.Linear(128,128),\n            nn.ReLU(),\n            nn.Linear(128,1)\n        )\n\n    def forward(self,proc,feat):\n        emb=self.embedding(proc)\n        x=torch.cat([emb,feat],dim=2)\n        out,_=self.lstm(x)\n        return self.fc(out[:,-1,:])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T08:36:30.468639Z","iopub.execute_input":"2026-02-22T08:36:30.469357Z","iopub.status.idle":"2026-02-22T08:36:30.474590Z","shell.execute_reply.started":"2026-02-22T08:36:30.469325Z","shell.execute_reply":"2026-02-22T08:36:30.473906Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def compute_metrics(y_true, y_pred):\n    rmse = np.sqrt(mean_squared_error(y_true,y_pred))\n    mae  = mean_absolute_error(y_true,y_pred)\n    r2   = r2_score(y_true,y_pred)\n    return rmse, mae, r2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T08:36:33.473172Z","iopub.execute_input":"2026-02-22T08:36:33.473925Z","iopub.status.idle":"2026-02-22T08:36:33.477719Z","shell.execute_reply.started":"2026-02-22T08:36:33.473894Z","shell.execute_reply":"2026-02-22T08:36:33.476942Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def evaluate_model(model, df):\n\n    model.eval()\n    results=[]\n\n    for pid in df[\"process_id\"].unique():\n\n        subset=df[df[\"process_id\"]==pid]\n        ds=MemoryDataset(subset)\n        loader=DataLoader(ds,batch_size=64)\n\n        preds,ys=[],[]\n\n        with torch.no_grad():\n            for p,f,y in loader:\n                p,f=p.to(DEVICE),f.to(DEVICE)\n                out=model(p,f)\n                preds.extend(out.cpu().numpy())\n                ys.extend(y.numpy())\n\n        rmse,mae,r2=compute_metrics(ys,preds)\n\n        results.append({\n            \"Process\":pid,\n            \"RMSE\":rmse,\n            \"MAE\":mae,\n            \"R2\":r2\n        })\n\n    return pd.DataFrame(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T08:36:38.619092Z","iopub.execute_input":"2026-02-22T08:36:38.619584Z","iopub.status.idle":"2026-02-22T08:36:38.625333Z","shell.execute_reply.started":"2026-02-22T08:36:38.619557Z","shell.execute_reply":"2026-02-22T08:36:38.624634Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def train_model(model,loader,epochs=15):\n\n    optimizer=optim.Adam(model.parameters(),lr=0.001)\n    criterion=nn.MSELoss()\n\n    for epoch in range(1,epochs+1):\n\n        model.train()\n        total_loss=0\n        grad_norm_total=0\n\n        for p,f,y in loader:\n            p,f,y=p.to(DEVICE),f.to(DEVICE),y.to(DEVICE)\n\n            optimizer.zero_grad()\n            pred=model(p,f)\n            loss=criterion(pred,y)\n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n            total_norm=0\n            for param in model.parameters():\n                if param.grad is not None:\n                    total_norm += param.grad.data.norm(2).item()\n\n            grad_norm_total+=total_norm\n\n            optimizer.step()\n            total_loss+=loss.item()\n\n        print(f\"Epoch {epoch:02d} | Loss {total_loss/len(loader):.4f} | GradNorm {grad_norm_total/len(loader):.4f}\")\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T08:36:41.242698Z","iopub.execute_input":"2026-02-22T08:36:41.243373Z","iopub.status.idle":"2026-02-22T08:36:41.249256Z","shell.execute_reply.started":"2026-02-22T08:36:41.243345Z","shell.execute_reply":"2026-02-22T08:36:41.248478Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def unlearn(model,target_loader,remain_loader):\n\n    criterion=nn.MSELoss()\n\n    # ---- Phase 1: Erase target ----\n    optimizer=optim.Adam(model.parameters(),lr=0.0005)\n\n    print(\"\\n--- Unlearning Phase 1 (Gradient Ascent on Target) ---\")\n    for epoch in range(1,3):\n\n        total_loss=0\n\n        for p,f,y in target_loader:\n            p,f,y=p.to(DEVICE),f.to(DEVICE),y.to(DEVICE)\n            optimizer.zero_grad()\n            pred=model(p,f)\n            loss=criterion(pred,y)\n            ascent_loss = torch.clamp(loss, max=5.0)\n            (-ascent_loss).backward()\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n\n            total_loss+=loss.item()\n\n        print(f\"Unlearn Epoch {epoch} | Target Loss {total_loss/len(target_loader):.4f}\")\n\n    # ---- Phase 2: Restore remaining ----\n    optimizer=optim.Adam(model.parameters(),lr=0.001)\n\n    print(\"\\n--- Unlearning Phase 2 (Recovery on Remaining) ---\")\n    for epoch in range(1,6):\n\n        total_loss=0\n\n        for p,f,y in remain_loader:\n            p,f,y=p.to(DEVICE),f.to(DEVICE),y.to(DEVICE)\n            optimizer.zero_grad()\n            pred=model(p,f)\n            loss=criterion(pred,y)\n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n\n            total_loss+=loss.item()\n\n        print(f\"Recovery Epoch {epoch} | Remaining Loss {total_loss/len(remain_loader):.4f}\")\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T08:36:43.813456Z","iopub.execute_input":"2026-02-22T08:36:43.813995Z","iopub.status.idle":"2026-02-22T08:36:43.821447Z","shell.execute_reply.started":"2026-02-22T08:36:43.813950Z","shell.execute_reply":"2026-02-22T08:36:43.820667Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"df=generate_dataset()\n\nle=LabelEncoder()\ndf[\"process_encoded\"]=le.fit_transform(df[\"process_id\"])\n\nfeature_scaler = StandardScaler()\ntarget_scaler  = StandardScaler()\n\ndf[[\"previous_memory\",\"cpu_usage\"]] = feature_scaler.fit_transform(\n    df[[\"previous_memory\",\"cpu_usage\"]]\n)\n\ndf[\"memory_usage_next\"] = target_scaler.fit_transform(\n    df[[\"memory_usage_next\"]]\n)\n\ntrain_df,test_df=train_test_split(df,test_size=0.2,random_state=42)\n\ntrain_loader=DataLoader(MemoryDataset(train_df),batch_size=64,shuffle=True)\n\nmodel=DeepLSTM(len(le.classes_)).to(DEVICE)\n\nprint(\"\\n===== TRAINING START =====\")\nmodel=train_model(model,train_loader)\n\nprint(\"\\n===== BASELINE METRICS =====\")\nbaseline_metrics=evaluate_model(model,test_df)\nprint(baseline_metrics)\n\ntarget_process=\"P3\"\n\ntarget_loader=DataLoader(\n    MemoryDataset(train_df[train_df[\"process_id\"]==target_process]),\n    batch_size=64,shuffle=True)\n\nremain_loader=DataLoader(\n    MemoryDataset(train_df[train_df[\"process_id\"]!=target_process]),\n    batch_size=64,shuffle=True)\n\nprint(\"\\n===== UNLEARNING START =====\")\nmodel_un=DeepLSTM(len(le.classes_)).to(DEVICE)\nmodel_un.load_state_dict(model.state_dict())\n\nmodel_un=unlearn(model_un,target_loader,remain_loader)\n\nprint(\"\\n===== AFTER UNLEARNING METRICS =====\")\nafter_metrics=evaluate_model(model_un,test_df)\nprint(after_metrics)\n\n# Certified forgetting score\nbefore_target = baseline_metrics[baseline_metrics[\"Process\"]==target_process][\"RMSE\"].values[0]\nafter_target  = after_metrics[after_metrics[\"Process\"]==target_process][\"RMSE\"].values[0]\n\nprint(\"\\nCertified Forgetting Score (RMSE increase on target):\",\n      after_target - before_target)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T08:36:46.217781Z","iopub.execute_input":"2026-02-22T08:36:46.218088Z","iopub.status.idle":"2026-02-22T08:38:56.692635Z","shell.execute_reply.started":"2026-02-22T08:36:46.218064Z","shell.execute_reply":"2026-02-22T08:38:56.691902Z"}},"outputs":[{"name":"stdout","text":"\n===== TRAINING START =====\nEpoch 01 | Loss 0.1496 | GradNorm 1.7784\nEpoch 02 | Loss 0.0072 | GradNorm 0.9861\nEpoch 03 | Loss 0.0040 | GradNorm 0.6358\nEpoch 04 | Loss 0.0041 | GradNorm 0.7191\nEpoch 05 | Loss 0.0046 | GradNorm 0.7194\nEpoch 06 | Loss 0.0037 | GradNorm 0.6841\nEpoch 07 | Loss 0.0028 | GradNorm 0.5789\nEpoch 08 | Loss 0.0025 | GradNorm 0.5332\nEpoch 09 | Loss 0.0028 | GradNorm 0.5603\nEpoch 10 | Loss 0.0027 | GradNorm 0.5124\nEpoch 11 | Loss 0.0022 | GradNorm 0.4636\nEpoch 12 | Loss 0.0022 | GradNorm 0.4513\nEpoch 13 | Loss 0.0020 | GradNorm 0.4372\nEpoch 14 | Loss 0.0022 | GradNorm 0.4566\nEpoch 15 | Loss 0.0021 | GradNorm 0.4401\n\n===== BASELINE METRICS =====\n  Process      RMSE       MAE        R2\n0      P7  0.131094  0.103638  0.983245\n1      P4  0.016220  0.012752  0.903964\n2      P8  0.021846  0.018410 -0.073696\n3      P0  0.005152  0.004285  0.995568\n4      P3  0.012078  0.010293 -0.395236\n5      P2  0.012953  0.010199  0.885363\n6      P1  0.056434  0.051549  0.985968\n7      P5  0.008050  0.006194  0.198743\n8      P6  0.007699  0.006412  0.993549\n9      P9  0.093034  0.087242  0.994502\n\n===== UNLEARNING START =====\n\n--- Unlearning Phase 1 (Gradient Ascent on Target) ---\nUnlearn Epoch 1 | Target Loss 7.2158\nUnlearn Epoch 2 | Target Loss 29.8554\n\n--- Unlearning Phase 2 (Recovery on Remaining) ---\nRecovery Epoch 1 | Remaining Loss 0.0817\nRecovery Epoch 2 | Remaining Loss 0.0024\nRecovery Epoch 3 | Remaining Loss 0.0031\nRecovery Epoch 4 | Remaining Loss 0.0021\nRecovery Epoch 5 | Remaining Loss 0.0028\n\n===== AFTER UNLEARNING METRICS =====\n  Process      RMSE       MAE            R2\n0      P7  0.126311  0.101916      0.984446\n1      P4  0.023869  0.017213      0.792017\n2      P8  0.021633  0.018103     -0.052850\n3      P0  0.012950  0.010992      0.971999\n4      P3  2.443270  2.443237 -57092.709268\n5      P2  0.026242  0.021901      0.529527\n6      P1  0.034787  0.025500      0.994668\n7      P5  0.009197  0.006794     -0.045971\n8      P6  0.023578  0.022279      0.939491\n9      P9  0.073009  0.065746      0.996614\n\nCertified Forgetting Score (RMSE increase on target): 2.4311919015860424\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# =====================================================\n# PROCESS-WISE RMSE + R2 COMPARISON TABLE\n# =====================================================\n\ncomparison_rows = []\n\nfor pid in baseline_metrics[\"Process\"]:\n\n    before_rmse = baseline_metrics[\n        baseline_metrics[\"Process\"] == pid][\"RMSE\"].values[0]\n\n    after_rmse = after_metrics[\n        after_metrics[\"Process\"] == pid][\"RMSE\"].values[0]\n\n    before_r2 = baseline_metrics[\n        baseline_metrics[\"Process\"] == pid][\"R2\"].values[0]\n\n    after_r2 = after_metrics[\n        after_metrics[\"Process\"] == pid][\"R2\"].values[0]\n\n    comparison_rows.append({\n        \"Process\": pid,\n        \"Before RMSE\": round(before_rmse, 6),\n        \"After RMSE\": round(after_rmse, 6),\n        \"Before R2\": round(before_r2, 6),\n        \"After R2\": round(after_r2, 6)\n    })\n\ncomparison_df = pd.DataFrame(comparison_rows)\n\nprint(\"\\n===== PROCESS-WISE RMSE + R2 COMPARISON =====\\n\")\nprint(comparison_df.sort_values(\"Process\").reset_index(drop=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T08:41:00.971185Z","iopub.execute_input":"2026-02-22T08:41:00.971926Z","iopub.status.idle":"2026-02-22T08:41:00.994172Z","shell.execute_reply.started":"2026-02-22T08:41:00.971889Z","shell.execute_reply":"2026-02-22T08:41:00.993356Z"}},"outputs":[{"name":"stdout","text":"\n===== PROCESS-WISE RMSE + R2 COMPARISON =====\n\n  Process  Before RMSE  After RMSE  Before R2      After R2\n0      P0     0.005152    0.012950   0.995568      0.971999\n1      P1     0.056434    0.034787   0.985968      0.994668\n2      P2     0.012953    0.026242   0.885363      0.529527\n3      P3     0.012078    2.443270  -0.395236 -57092.709268\n4      P4     0.016220    0.023869   0.903964      0.792017\n5      P5     0.008050    0.009197   0.198743     -0.045971\n6      P6     0.007699    0.023578   0.993549      0.939491\n7      P7     0.131094    0.126311   0.983245      0.984446\n8      P8     0.021846    0.021633  -0.073696     -0.052850\n9      P9     0.093034    0.073009   0.994502      0.996614\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}